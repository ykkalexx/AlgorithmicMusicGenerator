import * as mm from "@magenta/music";
import * as Tone from "tone";
import { MOODS } from "@/constants/constants";
import { MoodKey, MusicEvent } from "@/types/types";

interface NoteSequence extends mm.INoteSequence {
  notes: mm.NoteSequence.Note[];
  totalTime: number;
  tempos: Array<{ time: number; qpm: number }>;
}

export class MagentaService {
  private musicRNN: mm.MusicRNN;
  private musicVAE: mm.MusicVAE;
  private initialized: boolean = false;

  constructor() {
    // initializing both RNN and VAE models
    this.musicRNN = new mm.MusicRNN(
      "https://storage.googleapis.com/magentadata/js/checkpoints/music_rnn/mel_4bar"
    );
    this.musicVAE = new mm.MusicVAE(
      "https://storage.googleapis.com/magentadata/js/checkpoints/music_vae/mel_4bar"
    );
  }

  async initialize() {
    if (!this.initialize) {
      await Promise.all([
        this.musicRNN.initialize(),
        this.musicVAE.initialize(),
      ]);
      this.initialized = true;
    }
  }

  // generateMelody is used to generate a melody based on the mood
  // The mood is defined in the MOODS constant
  // The melody is generated by the Magenta.js library
  async generateMelody(mood: MoodKey): Promise<MusicEvent[]> {
    if (!this.initialized) {
      await this.initialize();
    }

    const moodConfig = MOODS.find((m) => m.value === mood);
    if (!moodConfig) {
      throw new Error("Invalid mood");
    }

    // Create sequence based on mood
    const seed = this.createSeedSequence(moodConfig.scale);

    // Initial sequence using VAE
    const z = await this.musicVAE.encode([seed as mm.INoteSequence]);
    const sample = await this.musicVAE.decode(z, 1.0);

    if (!sample[0] || !sample[0].notes) {
      throw new Error("Failed to generate sample sequence");
    }

    // Use RNN to extend the sequence
    const continuation = await this.musicRNN.continueSequence(
      sample[0],
      32, // steps
      moodConfig.tempo.max / 60 // fixed to use tempo.max
    );

    if (!continuation || !continuation.notes) {
      throw new Error("Failed to generate continuation sequence");
    }

    // Convert the sequence to music events
    return this.convertToMusicEvents(continuation as NoteSequence, moodConfig);
  }

  // createSeedSequence is used to create a seed sequence based on the scale
  // The scale is defined in the MOODS constant
  // The seed sequence is used to generate a melody
  // The melody is generated by the Magenta.js library
  private createSeedSequence(scale: string[]): NoteSequence {
    const sequence: NoteSequence = {
      notes: [],
      totalTime: 4,
      tempos: [{ time: 0, qpm: 120 }],
    };

    scale.forEach((note, i) => {
      const noteObj = {
        pitch: this.noteToPitch(note),
        startTime: i * 0.5,
        endTime: (i + 1) * 0.5,
        velocity: 100,
        program: 0,
        isDrum: false,
      } as mm.NoteSequence.Note;

      sequence.notes.push(noteObj);
    });

    return sequence;
  }

  // convert to music events is used to convert the note sequence to music events
  // which is used by the Tone.js library to play the music
  // The note sequence is generated by the Magenta.js library
  // prettier-ignore
  private convertToMusicEvents(sequence: NoteSequence, moodConfig: any): MusicEvent[] {
    const events: MusicEvent[] = [];
    
    sequence.notes.forEach((note) => {
      const duration = note.endTime - note.startTime;
      
      events.push({
        note: this.pitchToNote(note.pitch),
        duration: this.quantizeDuration(duration),
        time: note.startTime,
        velocity: this.normalizeVelocity(note.velocity, moodConfig),
      });
    });

    return events;
  }

  // noteToPitch is used to convert a note to a pitch
  // The pitch is used by the Tone.js library to play the music
  private noteToPitch(note: string): number {
    // prettier-ignore
    const notes = ["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"];
    const [noteName, octave] = note.match(/([A-G]#?)(\d+)/)?.slice(1) || [];
    if (!noteName || !octave) return 60;

    return notes.indexOf(noteName) + (parseInt(octave) + 1) * 12;
  }

  // pitchToNote is used to convert a pitch to a note
  // The note is used by the Tone.js library to play the music
  private pitchToNote(pitch: number): string {
    // prettier-ignore
    const notes = ["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"];
    const octave = Math.floor(pitch / 12) - 1;
    const note = notes[pitch % 12];
    return `${note}${octave}`;
  }

  // quantizeDuration is used to quantize the duration of the notes
  private quantizeDuration(duration: number): string {
    // converting duration to nearest note value
    const durations = {
      0.125: "32n",
      0.25: "16n",
      0.5: "8n",
      1: "4n",
      2: "2n",
      4: "1n",
    };

    let closest = Object.entries(durations).reduce((prev, curr) => {
      return Math.abs((curr[0] as any) - duration) <
        Math.abs((prev[0] as any) - duration)
        ? curr
        : prev;
    });

    return closest[1];
  }

  private normalizeVelocity(velocity: number, moodConfig: any): number {
    // Scale velocity to mood range
    const normalized = velocity / 127; // MIDI velocity to 0-1
    const range = moodConfig.velocity.max - moodConfig.velocity.min;
    return moodConfig.velocity.min + normalized * range;
  }

  // interpolate is used to interpolate between two sequences
  // The sequences are generated by the Magenta.js library
  // prettier-ignore
  async interpolate(sequence1: MusicEvent[], sequence2: MusicEvent[], steps: number = 4 ): Promise<MusicEvent[][]> {
    if (!this.initialized) {
      await this.initialize();
    }

    const seq1 = this.convertToMagentaSequence(sequence1) as mm.INoteSequence;
    const seq2 = this.convertToMagentaSequence(sequence2) as mm.INoteSequence;

    const z1 = await this.musicVAE.encode([seq1]);
    const z2 = await this.musicVAE.encode([seq2]);

    const interpolations = await this.musicVAE.interpolate([seq1, seq2], steps);
    
    return interpolations.map(seq => 
      this.convertToMusicEvents(seq as NoteSequence, {
        tempo: { min: 60, max: 120 },
        velocity: { min: 0.5, max: 1 }
      })
    );
  }

  private convertToMagentaSequence(events: MusicEvent[]): mm.INoteSequence {
    const sequence: NoteSequence = {
      notes: [],
      totalTime: 0,
      tempos: [{ time: 0, qpm: 120 }],
    };

    events.forEach((event) => {
      const duration = Tone.Time(event.duration).toSeconds();
      const baseNote: Partial<mm.NoteSequence.Note> = {
        pitch: 0,
        startTime: event.time || 0,
        endTime: (event.time || 0) + duration,
        velocity: Math.floor((event.velocity || 1) * 127),
        program: 0,
        isDrum: false,
        instrument: 0,
        quantizedStartStep: 0,
        quantizedEndStep: 0,
      };

      if (Array.isArray(event.note)) {
        event.note.forEach((note) => {
          sequence.notes.push({
            ...baseNote,
            pitch: this.noteToPitch(note),
          } as mm.NoteSequence.Note);
        });
      } else {
        sequence.notes.push({
          ...baseNote,
          pitch: this.noteToPitch(event.note),
        } as mm.NoteSequence.Note);
      }
    });

    sequence.totalTime = Math.max(...sequence.notes.map((n) => n.endTime));
    return sequence;
  }

  dispose() {
    if (this.initialized) {
      this.musicRNN.dispose();
      this.musicVAE.dispose();
      this.initialized = false;
    }
  }
}
